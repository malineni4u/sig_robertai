
# ü§ñ GenAI-Powered Integrated Platform Environment

![Agentic AI](https://img.shields.io/badge/Powered_by-Agentic_AI-blueviolet)
![Context-Aware](https://img.shields.io/badge/Contextual-Recommendations-blue)
![Streamlit](https://img.shields.io/badge/Built_with-Streamlit-orange)

**Sigma-AI** is a **GenAI-enabled** Integrated Platform Environment (IPE) that empowers platform engineers by reducing context switching across tools. It brings observability, RCA generation, network analysis, and intelligent insights into a unified interface using vector search, CMDB correlations, and LLM-powered workflows.

---

## Table of Contents

1. [User-Interface Overview](#user-interface-overview)
2. [Power of Two Models ‚Äì Smart Fallback](#-power-of-two-models--smart-fallback)
3. [Incident Similarity Search with Gaussian Distance](#-incident-similarity-search-with-gaussian-distance)
4. [Intelligence Stack](#-intelligence-stack)
5. [Project Structure](#project-structure)
6. [System Architecture](#system-architecture)
7. [LLM & Intelligence Stack](#llm--intelligence-stack)
8. [Installation](#installation)
9. [Configuration](#configuration)
10. [Running the Application](#running-the-application)
11. [Usage](#usage)
12. [Troubleshooting](#troubleshooting)
13. [License](#license)
14. [Acknowledgments](#acknowledgments)

---

## üñ•Ô∏è User-Interface Overview

![Sigma-AI UI Preview](docs/sigma_ui_preview.jpg)

- üß† **Smart Issue Explorer**  
  Convert any natural language issue into vector embeddings and search similar incidents. Get RCA and related CRs powered by LLMs. 
    - Converts it into vector embeddings
    - Uses FAISS with Gaussian Distance to find similar past incidents
    - Uses GenAI (LLMs) to provide:
      - Contextual incident matches
      - Relevant RCA suggestions
      - Correlated CRs (Change Requests) based on CI and timing
      - Helpful resolution summaries 
  
- üßæ **Incident Investigator**  
  Enter a specific incident ID to generate contextual RCA, show related CRs, and suggest resolution.  
    - Retrieves historical matches
    - Applies LLM to generate a **Root Cause Analysis (RCA)**
    - Suggests probable causes and next steps
  
- üß¨ **TraceIQ**  
  Feed logs from APIs, analyze them using LLMs, and receive suggestions based on trace ID and log content.  
    - Reads logs from connected log injection APIs
    - Applies LLM to suggest possible fixes
    - Helps platform teams derive meaning from complex logs

- üåê **NetViz Explorer**  
  Visualize app-to-CI/API dependencies using CMDB mapping and explore how components are connected.  
    - Builds a **dynamic network diagram** from CMDB data
    - Displays app-to-CI/API relationships
    - Helps teams understand dependency paths and potential breakpoints
  
- üí¨ **Agentic Chatbot**  
  Ask questions, explore suggestions, and receive guidance directly through an LLM-powered assistant.
  - Self-help for generalized platform queries
  - Guidance on Sigma-AI usage
  - Fast answers to system and RCA-related questions
  - Direct interaction with knowledge embedded from your incidents, CRs, and CMDB

---

## üîÅ Power of Two Models ‚Äì Smart Fallback

Sigma-AI intelligently uses:
- ‚ö° **Primary**: OpenAI GPT-3.5 for RCA generation
- üîÑ **Fallback**: Hugging Face Mistral 7B when OpenAI quota limits apply

---

---

---

## üìê Incident Similarity Search with L2 (Euclidean) Distance

Sigma-AI uses **FAISS** for high-performance similarity search based on **squared Euclidean (L2) distance**. This is used to compare vector embeddings and retrieve semantically similar incidents.

### üìè L2 (Euclidean) Distance

The standard Euclidean distance between two vectors **x** and **y** is:

<div align="center">

$$
\\text{distance} = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + \\cdots + (x_n - y_n)^2}
$$

</


---


---

## üß† Intelligence Stack

Sigma-AI brings together multiple components to power its intelligence:

- üî° **Embedding Model**: `all-MiniLM-L6-v2` from SentenceTransformers  
- üîç **Vector Search Engine**: FAISS  
- üß† **LLMs**:
  - OpenAI GPT-3.5
  - Hugging Face's Mistral 7B
  - `LaMini-Flan-T5-783M`

---

## üìÇ Project Structure

```
.
‚îú‚îÄ‚îÄ streamlit_app.py
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ data_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ vector_search.py
‚îÇ   ‚îú‚îÄ‚îÄ model_runner.py
‚îÇ   ‚îú‚îÄ‚îÄ change_checker.py
‚îÇ   ‚îî‚îÄ‚îÄ log_checker.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ incident_data.csv
‚îÇ   ‚îú‚îÄ‚îÄ change.csv
‚îÇ   ‚îú‚îÄ‚îÄ CMDB_Mapping.csv
‚îÇ   ‚îî‚îÄ‚îÄ Logs_Lookup.csv
‚îî‚îÄ‚îÄ requirements.txt
```

---

## System Architecture

```
User Input (Incident ID or Free Text)
        |
[Embedding Model: all-MiniLM-L6-v2]
        |
   [Vector Embedding]
        |
FAISS Similarity Search (Gaussian Distance)
        |
Retrieve Top-K Similar Incidents
        |
[LLM: GPT / Mistral]
‚Üí RCA Generation   ‚Üí Resolution Suggestion
        |
CR + Log Correlation (CMDB + Trace ID)
```

---

## LLM & Intelligence Stack

- üî° **Embedding**: `all-MiniLM-L6-v2`
- üîç **Vector DB**: FAISS (Gaussian Distance)  
- üß† **LLMs**:
  - OpenAI GPT-3.5
  - Mistral 7B
  - LaMini-Flan-T5-783M

---

## Installation

```bash
git clone https://github.com/your-username/sigma-ai.git
cd sigma-ai
pip install -r requirements.txt
```

---

## Configuration

```bash
export OPENAI_API_KEY=your-key
```

---

## Running the Application

```bash
streamlit run streamlit_app.py
```

---

## Usage

1. Use Smart Issue Explorer to describe symptoms.
2. Use Incident Investigator with an incident ID.
3. Use TraceIQ for log analysis.
4. Use NetViz Explorer for dependency mapping.
5. Use the chatbot for self-help queries.

---

## Troubleshooting

- Ensure OpenAI API key is configured.
- Confirm Hugging Face models are accessible or installed.
- Ensure log injection APIs are operational.

---

## License

MIT License

---

## Acknowledgments

- Hugging Face
- OpenAI
- Streamlit
- FAISS team
